{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient, login\n",
    "import sqlite3\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "login(os.getenv('HF_TOKEN'))\n",
    "hf_model = \"mistralai/Mistral-7B-Instruct-v0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(cte_object) -> str:\n",
    "  client = InferenceClient(model=hf_model)\n",
    "  messages = [\n",
    "      {'role':'user',\n",
    "       'content':f\"Explain in one sentence what this SQL code is doing:\\n\\n{cte_object.get('SQL')}\"\n",
    "       }\n",
    "       ]\n",
    "  response = client.chat_completion(messages, max_tokens=2000, seed=42, temperature=0)\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_json_files(file_path):\n",
    "    \"\"\"\n",
    "    makes requests to the Hugging Face API to generate summaries for each CTE in the JSON file.\n",
    "    returns a status code because hugging face has an hourly request limit.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r+', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        for i, obj in enumerate(data):\n",
    "            if \"summary\" not in obj or not obj[\"summary\"]:\n",
    "                try:\n",
    "                    obj[\"summary\"] = get_summary(obj)\n",
    "                    # Overwrite the file immediately after generating the summary\n",
    "                    file.seek(0)\n",
    "                    json.dump(data, file, indent=2)\n",
    "                    file.truncate()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error generating summary for {file_path} at index {i}: {e}\")\n",
    "                    # Pause and return to allow rerun later\n",
    "                    return -1\n",
    "    return 0\n",
    "\n",
    "def sleep_until_next_hour():\n",
    "    now = datetime.now()\n",
    "    # Calculate the time until the next hour\n",
    "    next_hour = (now + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)\n",
    "    sleep_time = (next_hour - now).total_seconds()\n",
    "    print(f\"Sleeping for {int(sleep_time // 60)} minutes until {next_hour}.\")\n",
    "    time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = -1\n",
    "while result != 0:\n",
    "    result = generate_json_files('spider/spider2-lite-ctes.json')\n",
    "    if result == -1:\n",
    "        sleep_until_next_hour()\n",
    "    elif result == 0:\n",
    "        print(\"Finished successfully.\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
